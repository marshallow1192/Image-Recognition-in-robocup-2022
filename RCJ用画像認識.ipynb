{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 446 images belonging to 3 classes.\n",
      "Found 608 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.7130INFO:tensorflow:Assets written to: ./models/RCJ_Image_Recognition/model 1.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/RCJ_Image_Recognition/model 1.pb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 30s 259ms/step - loss: 0.6811 - accuracy: 0.7130 - val_loss: 0.4713 - val_accuracy: 0.7961\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9305INFO:tensorflow:Assets written to: ./models/RCJ_Image_Recognition/model 2.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/RCJ_Image_Recognition/model 2.pb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 30s 273ms/step - loss: 0.2435 - accuracy: 0.9305 - val_loss: 0.3320 - val_accuracy: 0.8799\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9552INFO:tensorflow:Assets written to: ./models/RCJ_Image_Recognition/model 3.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/RCJ_Image_Recognition/model 3.pb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.1488 - accuracy: 0.9552 - val_loss: 0.3457 - val_accuracy: 0.8651\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from  tensorflow.keras.applications import ResNet50, vgg16\n",
    "from  tensorflow.keras.models import Sequential, Model\n",
    "from  tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from  tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "#画像サイズ\n",
    "imagesize = 96\n",
    "#データの前処理\n",
    "image_data_genelator = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255,shear_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   horizontal_flip=True,\n",
    "   rotation_range=10)\n",
    " \n",
    "train_generator = image_data_genelator.flow_from_directory(\n",
    "    \"./mask-model\",\n",
    "    target_size = (imagesize,imagesize),\n",
    "    color_mode='rgb',\n",
    "    classes = [\"model-H\",\"model-S\",\"model-U\"],\n",
    "    class_mode='categorical',\n",
    "    batch_size = 4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = image_data_genelator.flow_from_directory(\n",
    "    \"./test-mask-model\",\n",
    "    target_size = (imagesize,imagesize),\n",
    "    color_mode='rgb',\n",
    "    classes = [\"model-H\",\"model-S\",\"model-U\"],\n",
    "    class_mode='categorical',\n",
    "    batch_size = 4,\n",
    "    shuffle=True\n",
    ")\n",
    "#モデルの定義\n",
    "input_tensor = Input(shape=(imagesize, imagesize, 3))\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#callback関数の定義\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath =\"./models/RCJ_Image_Recognition/model{epoch:2d}.pb\",\n",
    "                                                                                 monitor='val_loss',\n",
    "                                                                                 save_best_only=False,\n",
    "                                                                                 save_weights_only=False,\n",
    "                                                                                 include_optimizer = False,\n",
    "                                                                                 mode='min',)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "#コマンドラインで、\"tensorboard --logdir logs/fit\"と入力しTensorboardを起動\n",
    "#学習\n",
    "history = model.fit(\n",
    "    train_generator ,\n",
    "    validation_data=test_generator ,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping,checkpoint,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 20:40:50.016437: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-07 20:40:50.016478: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-07 20:40:50.016794: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./models/RCJ_Image_Recognition/model06.pb\n",
      "2023-08-07 20:40:50.019650: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-07 20:40:50.019667: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./models/RCJ_Image_Recognition/model06.pb\n",
      "2023-08-07 20:40:50.027085: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-07 20:40:50.145997: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: ./models/RCJ_Image_Recognition/model06.pb\n",
      "2023-08-07 20:40:50.170460: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 153667 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./models/RCJ_Image_Recognition/model06.pb\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "start_time = time.time()\n",
    "image_size = 96\n",
    "classes = [\"H\",\"S\",\"U\"]\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "\n",
    "image = Image.open(\"model627.jpg\")\n",
    "image = image.convert('RGB')\n",
    "image = image.resize((image_size, image_size))\n",
    "data = np.asarray(image)/255\n",
    "X = []\n",
    "X.append(data)\n",
    "X = np.array(X, dtype=np.float32)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], X)\n",
    "\n",
    "# 推論実行\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(classes[np.argmax(output_data)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
